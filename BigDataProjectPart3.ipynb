{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf74641e",
   "metadata": {},
   "source": [
    "**Group 5**\n",
    "\n",
    "1. Lionel Rozario\n",
    "2. **FAIZALABBAS SAIYED**\n",
    "3. Sai Karthik Sana\n",
    "4. Nagul meera Shaik\n",
    "5. Rahul Thodupunoori\n",
    "6. Sasidhar Yellanki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f062825",
   "metadata": {},
   "source": [
    "# All Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddaeacc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn import metrics\n",
    "\n",
    "# fetch dataset\n",
    "diabetic_retinopathy_debrecen = fetch_ucirepo(id=329)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = diabetic_retinopathy_debrecen.data.features\n",
    "y = diabetic_retinopathy_debrecen.data.targets\n",
    "\n",
    "# variable information\n",
    "url = 'https://archive.ics.uci.edu/static/public/329/data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f6fe67",
   "metadata": {},
   "source": [
    "# Probabilistic Classifiier Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Class' column contains the target variable\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Mapping the labels for binary classification (0: No Diabetic Retinopathy, 1: Diabetic Retinopathy)\n",
    "y_binary = y.apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initializing and training the logistic regression model\n",
    "base_model = LogisticRegression(max_iter=1000)\n",
    "base_model.fit(X_train_scaled, y_train)  \n",
    "\n",
    "# Initializing and training the calibrated classifier\n",
    "calibrated_model = CalibratedClassifierCV(base_model, method='sigmoid', cv='prefit')\n",
    "calibrated_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting probabilities on the test set\n",
    "y_prob = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Converting probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluating the model\n",
    "probabilistic_accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix_probabilistic = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad405b48",
   "metadata": {},
   "source": [
    "***Binary Classifier:***\n",
    "\n",
    "**Original Labels:**\n",
    "\n",
    "* Initially, the target variable 'Class' is separated into two parts: features (X) and original labels (Y), which indicate whether a person has diabetic retinopathy (1) or not (0).\n",
    "\n",
    "**Modified Labels for Binary Classification:**\n",
    "\n",
    "* To fit the needs of a binary classification task, the original labels are adjusted. A new set of labels (y_binary) is created, where 1 indicates the presence of diabetic retinopathy, and 0 indicates its absence. This simplifies the task of the model.\n",
    "\n",
    "***Splitting the dataset:***\n",
    "* We are creating two sets of data: one for training a model and one for testing its accuracy. \n",
    "\n",
    "* It takes the features (like patient information) and the modified labels(y_binary) indicating if someone has diabetic retinopathy or not and splits them into two groups. \n",
    "\n",
    "* About 80% of the data is used to train the model, traininging it to make predictions. The remaining 20% is kept aside to test how well the model can predict on new data it hasn't seen before. This separation helps ensure the model is good at making predictions on different cases, not just the ones it learned from. \n",
    "\n",
    "* The use of random_state=42 ensures that the splitting is done in a consistent way, making it easier to compare results when the code is run multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ac42b",
   "metadata": {},
   "source": [
    "# Probabilistic Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy of Probabilistic Classification:\\n{probabilistic_accuracy}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n",
    "print(f\"conf_matrix_probabilistic:\\n{conf_matrix_probabilistic}\")\n",
    "\n",
    "cm_display_probabilistic = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_probabilistic, display_labels=[0, 1] )\n",
    "cm_display_probabilistic.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix Probabilistic Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c37ba5",
   "metadata": {},
   "source": [
    "***Results:***\n",
    "\n",
    "**Accuracy:**\n",
    "\n",
    "* The model is about 72% accurate, meaning it correctly predicts whether a person has diabetic retinopathy or not for roughly 72% of the cases.\n",
    "\n",
    "**Precision and Recall:**\n",
    "\n",
    "* It is better at identifying cases with diabetic retinopathy (precision: 80%) compared to identifying cases without it (precision: 65%). This means when the model says someone has diabetic retinopathy, it's right 80% of the time.\n",
    "\n",
    "* It is good at finding most of the actual cases with diabetic retinopathy (recall: 66%), but it may miss some cases without the condition (recall: 80%). This means it correctly identifies 66% of the people with diabetic retinopathy.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "The confusion matrix shows specific counts of correct and incorrect predictions. For this instance, it correctly predicted 82 cases with diabetic retinopathy and 84 cases without, but it incorrectly classified 21 cases without the condition as having it.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "The model is reasonably accurate but may need improvement in correctly identifying cases without diabetic retinopathy. Further adjustments can be made like fine-tuning the model, could enhance its performance. The confusion matrix provides a detailed breakdown of correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f58827",
   "metadata": {},
   "source": [
    "# Euclidean Distance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "Y = df['Class']\n",
    "\n",
    "# Reconsidering the labels for binary classification\n",
    "Y_binary = Y.apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Converting X to a NumPy array\n",
    "X = X.to_numpy()\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_binary, test_size=0.1, random_state=42)\n",
    "\n",
    "# Creating a KNN classifier\n",
    "model_distance = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "\n",
    "# Fitting the model on the training data\n",
    "model_distance.fit(X_train, Y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "predictions_distance = model_distance.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy_euclidean = accuracy_score(Y_test, predictions_distance)\n",
    "classification_report_euclidean = classification_report(Y_test, predictions_distance)\n",
    "conf_matrix_euclidean = confusion_matrix(Y_test, predictions_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed8df05",
   "metadata": {},
   "source": [
    "***Binary Classifier:***\n",
    "\n",
    "**Original Labels:**\n",
    "\n",
    "* Initially, the target variable 'Class' is separated into two parts: features (X) and original labels (Y), which indicate whether a person has diabetic retinopathy (1) or not (0).\n",
    "\n",
    "**Modified Labels for Binary Classification:**\n",
    "\n",
    "* To fit the needs of a binary classification task, the original labels are adjusted. A new set of labels (Y_binary) is created, where 1 indicates the presence of diabetic retinopathy, and 0 indicates its absence. This simplifies the task of the model.\n",
    "\n",
    "***Splitting the dataset:***\n",
    "* We are creating two sets of data: one for training a model and one for testing its accuracy. \n",
    "\n",
    "* It takes the features (like patient information) and the modified labels(Y_binary) indicating if someone has diabetic retinopathy or not and splits them into two groups. \n",
    "\n",
    "* About 80% of the data is used to train the model, traininging it to make predictions. The remaining 20% is kept aside to test how well the model can predict on new data it hasn't seen before. This separation helps ensure the model is good at making predictions on different cases, not just the ones it learned from. \n",
    "\n",
    "* The use of random_state=42 ensures that the splitting is done in a consistent way, making it easier to compare results when the code is run multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b8d95",
   "metadata": {},
   "source": [
    "# Euclidean Distance Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results\n",
    "print(f\"Accuracy (Euclidean Distance): {accuracy_euclidean}\")\n",
    "print(f\"Classification Report (Euclidean Distance):\\n{classification_report_euclidean}\")\n",
    "print(f\"Confusion Matrix (Euclidean Distance):\\n{conf_matrix_euclidean}\")\n",
    "\n",
    "cm_display_knn = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_euclidean, display_labels=[0, 1])\n",
    "cm_display_knn.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix Euclidean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c62d28",
   "metadata": {},
   "source": [
    "***Results:***\n",
    "\n",
    "**Accuracy:**\n",
    "\n",
    "* The model is about 68% accurate, meaning it correctly predicts whether a person has diabetic retinopathy or not for around 68% of the cases.\n",
    "\n",
    "**Precision and Recall:**\n",
    "\n",
    "* It performs slightly better at identifying cases without diabetic retinopathy (precision: 62%) compared to identifying cases with it (precision: 75%). This means when the model says someone has diabetic retinopathy, it's right 75% of the time.\n",
    "\n",
    "* It's better at finding most of the actual cases with diabetic retinopathy (recall: 65%), but it may miss some cases without the condition (recall: 73%). This means it correctly identifies 65% of the people with diabetic retinopathy.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "* The confusion matrix shows specific counts of correct and incorrect predictions. For instance, it correctly predicted 42 cases with diabetic retinopathy and 37 cases without, but it incorrectly classified 14 cases without the condition as having it.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "The KNN model with Euclidean distance is reasonably accurate. It's slightly better at identifying cases without diabetic retinopathy. The confusion matrix provides a detailed breakdown of correct and incorrect predictions, giving insights into where the model can be enhanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80975e",
   "metadata": {},
   "source": [
    "# Cosine Similarity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and target variable\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Computing cosine similarity\n",
    "cosine_matrix = cosine_similarity(X_test_scaled, X_train_scaled)\n",
    "\n",
    "# Using cosine similarity for classification with K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=11) \n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating accuracy,classification report and confusion matrix\n",
    "cosine_accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_cosine = classification_report(y_test, y_pred)\n",
    "conf_matrix_cosine = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e9858",
   "metadata": {},
   "source": [
    "* KNN can naturally handle binary classification tasks without explicit label modification. We are using cosine similarity as a distance metric is compatible with the original class labels, and the model is trained and evaluated based on these labels directly.\n",
    "\n",
    "***Splitting the Dataset:***\n",
    "\n",
    "* We are dividing the dataset into two parts: one for training a machine learning model and the other for testing the model's accuracy. \n",
    "\n",
    "* About 80% of the data is used for training, teaching the model to make predictions. The remaining 20% is kept aside to see how well the model can predict on new data it hasn't seen before. \n",
    "\n",
    "* The use of random_state=42 ensures that the data is split in a consistent way, making it easier to compare results when the code is run multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c13ae",
   "metadata": {},
   "source": [
    "# Cosine Similarity Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy:\\n{cosine_accuracy}\")\n",
    "print(f\"classification_report_cosine:\\n{classification_report_cosine}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_cosine}\")\n",
    "\n",
    "cm_display_cosine = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_cosine, display_labels=[0, 1])\n",
    "cm_display_cosine.plot(cmap='Blues', values_format='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627af91f",
   "metadata": {},
   "source": [
    "***Results:***\n",
    "\n",
    "**Accuracy:**\n",
    "\n",
    "* The model has an accuracy of about 67%, meaning it correctly predicts whether a person has diabetic retinopathy or not for approximately 67% of the cases.\n",
    "\n",
    "**Precision and Recall:**\n",
    "\n",
    "* Precision for predicting cases with diabetic retinopathy (class 1) is 73%, indicating that when the model predicts someone has diabetic retinopathy, it's correct about 73% of the time.\n",
    "\n",
    "* Recall for predicting cases without diabetic retinopathy (class 0) is 71%, meaning the model correctly identifies 71% of the actual cases without diabetic retinopathy.\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "* The confusion matrix shows specific counts of correct and incorrect predictions. For this instance, it correctly predicted 82 cases with diabetic retinopathy and 73 cases without, but it incorrectly classified 30 cases without the condition as having it.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "The KNN model with cosine similarity performs reasonably well. The accuracy indicates a fair overall performance, and the precision and recall values provide insights into how well the model is at correctly identifying positive and negative cases. Potential areas for improvement could involve fine-tuning the model to enhance its predictive capabilities. The confusion matrix further details the specific types of correct and incorrect predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
